### pkg/cache已存在，已经实现


# Kubexm 缓存设计 (`pkg/cache`)

本文档描述了 Kubexm 项目中 `pkg/cache` 包的设计与实现。该包旨在提供一个作用域隔离的、并发安全的内存键值存储机制，用于在系统执行的不同层级中缓存数据，以减少重复计算或数据获取，从而提升性能。

## 1. 缓存目标

`pkg/cache` 的主要目标是：

*   提供一种在不同执行作用域（Pipeline, Module, Task, Step）内共享和传递数据的机制。
*   缓存那些需要频繁读取但不常变化的数据，例如主机 Facts、计算结果、组件版本信息等。
*   确保缓存在并发环境下的线程安全。

## 2. 缓存接口与作用域

为了实现作用域隔离，`pkg/cache` 定义了四个核心接口，分别对应系统执行的不同层级：

*   **`PipelineCache`**: 数据作用域限定在单个 Pipeline 的整个执行周期内。
*   **`ModuleCache`**: 数据作用域限定在单个 Module 的执行周期内。
*   **`TaskCache`**: 数据作用域限定在单个 Task 的执行周期内。
*   **`StepCache`**: 数据作用域限定在单个 Step 的执行周期内。

所有这些接口都提供了以下基本方法：

*   `Get(key string) (interface{}, bool)`: 根据键获取值，如果键存在则返回对应值和 `true`，否则返回 `nil` 和 `false`。
*   `Set(key string, value interface{})`: 设置键值对。
*   `Delete(key string)`: 根据键删除值。

### 2.1. `StepCache` 的特殊方法

除了上述基本方法外，`StepCache` 接口还额外定义了两个用于处理当前步骤规约（元数据）的方法：

*   `SetCurrentStepSpec(spec interface{})`: 用于存储当前正在执行的 Step 的规约信息。
*   `GetCurrentStepSpec() (interface{}, bool)`: 用于获取当前 Step 的规约信息。

## 3. 核心实现: `genericCache`

所有上述缓存接口均由一个名为 `genericCache` 的内部结构体实现。

*   **底层存储**: `genericCache` 使用 Go 标准库中的 `sync.Map` 作为其底层键值存储。`sync.Map` 专为并发环境设计，能够安全地处理多个 goroutine 同时进行的读写操作，无需额外的显式锁定。
*   **核心方法**: `genericCache` 实现了 `Get`, `Set`, `Delete` 以及 `StepCache` 所需的 `SetCurrentStepSpec` 和 `GetCurrentStepSpec` 方法，这些方法直接操作底层的 `sync.Map`。

## 4. 工厂函数

为了方便创建不同作用域的缓存实例，`pkg/cache` 包提供了一组工厂函数：

*   `NewPipelineCache() PipelineCache`
*   `NewModuleCache() ModuleCache`
*   `NewTaskCache() TaskCache`
*   `NewStepCache() StepCache`

这些函数均返回一个新的 `genericCache` 实例，并将其适配到相应的接口类型。

## 5. 使用场景与集成

在 Kubexm 的执行流程中，`runtime.Context` 结构体负责为每个执行层级（Pipeline, Module, Task, Step）创建和管理相应的缓存实例。这意味着：

*   当一个新的 Pipeline 开始时，会为其创建一个 `PipelineCache` 实例。
*   在该 Pipeline 内部，当一个 Module 开始执行时，会为其创建一个 `ModuleCache` 实例（同时可以访问其所属 Pipeline 的 `PipelineCache`）。
*   类似地，Task 和 Step 执行时也会获得各自作用域的缓存实例，并能向上访问其父级作用域的缓存。

这种设计确保了数据的隔离性（一个 Task 的缓存不会意外污染另一个 Task 的缓存），同时也允许在必要时通过访问更高层级的缓存来共享数据。

## 6. 当前实现的局限性

当前的 `pkg/cache` 实现是一个纯内存缓存，并未包含以下高级特性：

*   缓存过期策略（TTL, TTI）。
*   缓存大小限制与淘汰策略（LRU, LFU）。
*   缓存持久化。

如果未来有这些需求，需要在现有基础上进行扩展。